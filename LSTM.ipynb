{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "\n",
    "import gensim.models.keyedvectors as word2vec\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import MaxPooling1D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_curve,  roc_auc_score, classification_report\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname) s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"FinalDataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = df[\"finalCleanText\"]\n",
    "label_stance = df[\"STANCE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_count = label_stance.value_counts()\n",
    "labels_count.plot(kind=\"bar\")\n",
    "print(label_stance.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tkr = RegexpTokenizer('[a-zA-Z@]+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_split = []\n",
    "for i, line in enumerate(tweets):\n",
    "    #print(line)\n",
    "    tweet = str(line).lower().split()\n",
    "    tweet = tkr.tokenize(str(tweet))\n",
    "    tweets_split.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tweets_split[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2vModel = word2vec.KeyedVectors.load_word2vec_format(r'GoogleNews-vectors-negative300.bin', binary=True, limit=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(tweets_split)\n",
    "X = tokenizer.texts_to_sequences(tweets_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlentweet = 30\n",
    "X = pad_sequences(X, maxlen=maxlentweet)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(input_dim=w2vModel.syn0.shape[0], output_dim=w2vModel.syn0.shape[1], weights=[w2vModel.syn0],\n",
    "                            input_length=X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_out = 150\n",
    "\n",
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(Conv1D(filters=64, kernel_size=5, activation='relu', padding='causal'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(LSTM(units=lstm_out))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, label_stance, test_size= 0.25, random_state = 13)\n",
    "X_test = pad_sequences(X_test, maxlen=maxlentweet)\n",
    "X_train = pad_sequences(X_train, maxlen=maxlentweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "history = model.fit(X_train, Y_train, epochs=35, verbose=1, batch_size=batch_size, validation_data =[X_test, Y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size=batch_size)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "cm = confusion_matrix(Y_test, y_pred)\n",
    "print(cm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing Accuracy : \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#F1 Score, Recall and Precision\n",
    "print(classification_report(Y_test, y_pred, target_names=['0', '1', '2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHotToCategorical(y_hot):\n",
    "    r,c = y_hot.shape\n",
    "    y = [y_hot[i].argmax() for i in range(r)]\n",
    "    return y\n",
    "def createConfusionMatrix(y_true_c,y_pred_c,classifier_name):\n",
    "    mapping = {2:\"Anti Govt\",0:\"Neutral\",1:\"Pro Govt\"}\n",
    "    y_true_c = oneHotToCategorical(y_true_c)\n",
    "    y_pred_c = oneHotToCategorical(y_pred_c)\n",
    "    y_true = [mapping[i] for i in y_true_c]\n",
    "    y_pred = [mapping[i] for i in y_pred_c]\n",
    "    labels = [mapping[key] for key in mapping]\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    title = \"Confusion Matrix of \"+ classifier_name\n",
    "    fig = plt.figure()\n",
    "    ax= plt.subplot()\n",
    "    fig.add_subplot(ax)\n",
    "    sns.heatmap(cm, annot=True, ax = ax);\n",
    "    ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');\n",
    "    ax.set_title(title);\n",
    "    ax.xaxis.set_ticklabels(labels); ax.yaxis.set_ticklabels(labels);\n",
    "    fig.savefig(title+\"2.png\",bbox_inches='tight')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_train = history.history['accuracy']\n",
    "# acc_val = history.history['val_accuracy']\n",
    "# createGraph(acc_train,'Training Accuracy',acc_val,'Validation Accuracy','Epochs','Accuracy','Training and Validation Accuracy Using Vanilla NN with Label Smoothing')\n",
    "# plt.plot(epochs, acc_train, 'g', label='Training accuracy')\n",
    "# plt.plot(epochs, acc_val, 'b', label='Validation accuracy')\n",
    "# plt.title('Training and Validation accuracy')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "loss_train = history.history['loss']\n",
    "loss_val = history.history['val_loss']\n",
    "epochs = range(1,36)\n",
    "\n",
    "# print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createGraph(acc_train,acc_train_label,acc_val,acc_val_label,x_label,y_label,title):\n",
    "    x_len = max(len(acc_train),len(acc_val))\n",
    "    x = [i for i in range(1,x_len+1)]\n",
    "    plt.plot(x, acc_train, 'o-', label=acc_train_label)\n",
    "    plt.plot(x, acc_val, 'o-', label=acc_val_label)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(title+'2.png',bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "createGraph(loss_train,'Training Loss',loss_val,'Validation Loss','Epochs','Loss','Training and Validation Loss Using LSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train = history.history['acc']\n",
    "acc_val = history.history['val_acc']\n",
    "createGraph(acc_train,'Training Accuracy',acc_val,'Validation Accuracy','Epochs','Accuracy','Training and Validation Accuracy Using LSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHot(y_inp):\n",
    "    y = np.zeros((len(y_inp),3))\n",
    "    for i in range(len(y_inp)):\n",
    "        y[i][int(y_inp[i][0])] = 1\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t = pd.Series(Y_test)\n",
    "yt = y_t.values.reshape(-1,1)\n",
    "print(yt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_one_hot = oneHot(yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "createConfusionMatrix(y_one_hot,model.predict(X_test),\"LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Y_test == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "for i in x:\n",
    "    if i ==True:\n",
    "        c+=1\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array(y_pred)\n",
    "Y_test = np.array(Y_test)\n",
    "mapping = {2:\"Anti Govt\",0:\"Neutral\",1:\"Pro Govt\"}\n",
    "labels = [mapping[key] for key in mapping]\n",
    "cm = confusion_matrix(Y_test, y_pred)\n",
    "title = \"Confusion Matrix of LSTM\"\n",
    "fig = plt.figure()\n",
    "ax= plt.subplot()\n",
    "fig.add_subplot(ax)\n",
    "sns.heatmap(cm, annot=True, ax = ax);\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');\n",
    "ax.set_title(title);\n",
    "# ax.xaxis.set_ticklabels(labels); ax.yaxis.set_ticklabels(labels);\n",
    "sns.heatmap(cm, annot=True)\n",
    "fig.savefig(title+\".png\",bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
